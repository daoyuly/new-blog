---
title: Agentic Design Patterns - Chapter 1_ Prompt Chaining
tags: AI agent 设计
abbrlink: 14285
date: 2025-10-06 08:05:02
---

# 第 1 章：提示词链

## 提示词链模式概述

提示词链（Prompt Chaining），有时也称为管道模式（Pipeline pattern），是利用大型语言模型（LLM）处理复杂任务时的一种强大范式。提示词链不是期望 LLM 在单一的、整体化的步骤中解决复杂问题，而是采用分而治之的策略。其核心思想是将原始复杂问题分解为一系列更小、更易管理的子问题。每个子问题通过专门设计的提示词单独处理，并且一个提示词的输出会作为输入传递给链中的下一个提示词。

这种顺序处理技术为与 LLM 的交互引入了模块化和清晰性。通过分解复杂任务，更容易理解和调试每个单独的步骤，使整个过程更加健壮和可解释。链中的每一步都可以精心设计和优化，专注于更大问题的特定方面，从而产生更准确和聚焦的输出。

一个步骤的输出作为下一个步骤的输入至关重要。这种信息传递建立了依赖链（因此得名），其中先前操作的上下文和结果指导后续处理。这使得 LLM 能够在其先前工作的基础上构建，完善理解，并逐步接近期望的解决方案。

此外，提示词链不仅仅是分解问题；它还支持外部知识和工具的集成。在每一步，LLM 都可以被指示与外部系统、API 或数据库交互，丰富其超越内部训练数据的知识和能力。这种能力极大地扩展了 LLM 的潜力，使它们不仅仅作为独立模型运行，而是作为更广泛智能系统的组成部分。

提示词链的重要性超越了简单的问题解决。它是构建复杂 AI Agent 的基础技术。这些 Agent 可以利用提示词链在动态环境中自主规划、推理和行动。通过战略性地构建提示词序列，Agent 可以参与需要多步推理、规划和决策的任务。这样的 Agent 工作流可以更紧密地模拟人类思维过程，从而实现与复杂领域和系统更自然有效的交互。

**单一提示词的局限性：** 对于多方面的任务，为 LLM 使用单一的复杂提示词可能效率低下，导致模型在约束和指令方面遇到困难，可能导致指令忽略（提示词的某些部分被忽视）、上下文漂移（模型失去对初始上下文的跟踪）、错误传播（早期错误被放大）、需要更长上下文窗口（模型获得的信息不足无法响应）以及幻觉（认知负荷增加导致错误信息的可能性）。例如，一个要求分析市场研究报告、总结发现、识别带数据点的趋势并起草电子邮件的查询可能会失败，因为模型可能总结得很好，但未能提取数据或正确起草电子邮件。

**通过顺序分解增强可靠性：** 提示词链通过将复杂任务分解为聚焦的顺序工作流来解决这些挑战，显著提高了可靠性和控制力。基于上面的例子，管道或链式方法可以描述如下：

1. 初始提示词（总结）："总结以下市场研究报告的主要发现：[文本]。" 模型的唯一焦点是总结，提高了这一初始步骤的准确性。
2. 第二个提示词（趋势识别）："使用摘要，识别前三个新兴趋势并提取支持每个趋势的具体数据点：[步骤 1 的输出]。" 此提示词现在更受约束，并直接建立在经过验证的输出之上。
3. 第三个提示词（电子邮件撰写）："向营销团队起草一封简明的电子邮件，概述以下趋势及其支持数据：[步骤 2 的输出]。"

这种分解允许对流程进行更精细的控制。每一步都更简单且更清晰，这减少了模型的认知负荷，并导致更准确和可靠的最终输出。这种模块化类似于计算管道，其中每个函数在执行特定操作后将结果传递给下一个。为了确保每个特定任务的准确响应，可以在每个阶段为模型分配不同的角色。例如，在给定的场景中，初始提示词可以被指定为"市场分析师"，后续提示词为"贸易分析师"，第三个提示词为"专家文档撰写者"，依此类推。

**结构化输出的作用：** 提示词链的可靠性高度依赖于步骤之间传递的数据完整性。如果一个提示词的输出不明确或格式不佳，后续提示词可能由于错误的输入而失败。为了缓解这一问题，指定结构化输出格式（如 JSON 或 XML）至关重要。

例如，趋势识别步骤的输出可以格式化为 JSON 对象：

```json
{
  "trends": [
    {
      "trend_name": "AI-Powered Personalization",
      "supporting_data": "73% of consumers prefer to do business with brands that use personal information to make their shopping experiences more relevant."
    },
    {
      "trend_name": "Sustainable and Ethical Brands",
      "supporting_data": "Sales of products with ESG-related claims grew 28% over the last five years, compared to 20% for products without."
    }
  ]
}
```

这种结构化格式确保数据是机器可读的，可以精确解析并插入到下一个提示词中，而不会产生歧义。这种做法最大限度地减少了解释自然语言可能产生的错误，是构建健壮的多步骤 LLM 系统的关键组成部分。

## 实际应用与用例

提示词链是一种多用途模式，在构建 Agent 系统时适用于广泛的场景。其核心效用在于将复杂问题分解为顺序的、可管理的步骤。以下是几个实际应用和用例：

**1. 信息处理工作流：** 许多任务涉及通过多次转换处理原始信息。例如，总结文档、提取关键实体，然后使用这些实体查询数据库或生成报告。提示词链可能如下所示：

* 提示词 1：从给定的 URL 或文档中提取文本内容。
* 提示词 2：总结清理后的文本。
* 提示词 3：从摘要或原始文本中提取特定实体（例如，姓名、日期、位置）。
* 提示词 4：使用实体搜索内部知识库。
* 提示词 5：生成包含摘要、实体和搜索结果的最终报告。

这种方法应用于自动化内容分析、AI 驱动的研究助手开发和复杂报告生成等领域。

**2. 复杂查询回答：** 回答需要多步推理或信息检索的复杂问题是一个主要用例。例如，"1929 年股市崩盘的主要原因是什么，政府政策如何应对？"

* 提示词 1：识别用户查询中的核心子问题（崩盘原因、政府响应）。
* 提示词 2：专门研究或检索有关 1929 年崩盘原因的信息。
* 提示词 3：专门研究或检索有关政府对 1929 年股市崩盘的政策响应的信息。
* 提示词 4：将步骤 2 和 3 的信息综合成对原始查询的连贯答案。

这种顺序处理方法是开发能够进行多步推理和信息综合的 AI 系统的核心。当查询无法从单个数据点回答，而是需要一系列逻辑步骤或来自不同来源的信息集成时，需要这样的系统。

例如，设计用于生成关于特定主题的综合报告的自动化研究 Agent 执行混合计算工作流。最初，系统检索大量相关文章。从每篇文章中提取关键信息的后续任务可以为每个来源并发执行。此阶段非常适合并行处理，其中独立的子任务同时运行以最大化效率。

然而，一旦完成单个提取，过程就变得本质上是顺序的。系统必须首先整理提取的数据，然后将其综合成连贯的草稿，最后审查和完善此草稿以生成最终报告。这些后期阶段中的每一个在逻辑上都依赖于前一个阶段的成功完成。这就是应用提示词链的地方：整理的数据作为综合提示词的输入，生成的综合文本成为最终审查提示词的输入。因此，复杂操作经常将独立数据收集的并行处理与综合和完善的依赖步骤的提示词链结合起来。

**3. 数据提取和转换：** 将非结构化文本转换为结构化格式通常通过迭代过程实现，需要顺序修改以提高输出的准确性和完整性。

* 提示词 1：尝试从发票文档中提取特定字段（例如，姓名、地址、金额）。
* 处理：检查是否提取了所有必需字段以及它们是否满足格式要求。
* 提示词 2（条件性）：如果字段缺失或格式错误，制作新提示词要求模型专门查找缺失/格式错误的信息，可能提供失败尝试的上下文。
* 处理：再次验证结果。如有必要重复。
* 输出：提供提取的、验证的结构化数据。

这种顺序处理方法特别适用于从表单、发票或电子邮件等非结构化来源进行数据提取和分析。例如，解决复杂的光学字符识别（OCR）问题，如处理 PDF 表单，通过分解的多步方法更有效地处理。

最初，使用大型语言模型从文档图像执行主要文本提取。随后，模型处理原始输出以规范化数据，在这一步中，它可能将数字文本（如"一千零五十"）转换为其数字等价物 1050。LLM 的一个重大挑战是执行精确的数学计算。因此，在随后的步骤中，系统可以将任何所需的算术运算委托给外部计算器工具。LLM 识别必要的计算，将规范化的数字馈送到工具，然后合并精确的结果。这种文本提取、数据规范化和外部工具使用的链式序列实现了最终的准确结果，这通常很难从单个 LLM 查询中可靠地获得。

**4. 内容生成工作流：** 复杂内容的创作是一个程序化任务，通常分解为不同的阶段，包括初始构思、结构大纲、起草和后续修订。

* 提示词 1：根据用户的一般兴趣生成 5 个主题想法。
* 处理：允许用户选择一个想法或自动选择最佳想法。
* 提示词 2：基于选定的主题，生成详细的大纲。
* 提示词 3：根据大纲中的第一点编写草稿部分。
* 提示词 4：根据大纲中的第二点编写草稿部分，提供前一部分作为上下文。对所有大纲点继续这样做。
* 提示词 5：审查和完善完整草稿的连贯性、语气和语法。

这种方法用于一系列自然语言生成任务，包括创意叙事、技术文档和其他形式的结构化文本内容的自动创作。

**5. 具有状态的对话 Agent：** 尽管全面的状态管理架构采用比顺序链接更复杂的方法，提示词链提供了保持对话连续性的基础机制。这种技术通过将每个对话轮次构建为新提示词来维护上下文，该提示词系统地合并来自对话序列中先前交互的信息或提取的实体。

* 提示词 1：处理用户话语 1，识别意图和关键实体。
* 处理：使用意图和实体更新对话状态。
* 提示词 2：基于当前状态，生成响应和/或识别下一个所需的信息片段。
* 对于后续轮次重复，每个新的用户话语启动一个利用累积对话历史（状态）的链。

这一原则是开发对话 Agent 的基础，使它们能够在扩展的、多轮对话中保持上下文和连贯性。通过保留对话历史，系统可以理解并适当响应依赖于先前交换信息的用户输入。

**6. 代码生成和完善：** 功能代码的生成通常是一个多阶段过程，需要将问题分解为逐步执行的离散逻辑操作序列。

* 提示词 1：理解用户对代码函数的请求。生成伪代码或大纲。
* 提示词 2：基于大纲编写初始代码草稿。
* 提示词 3：识别代码中的潜在错误或改进领域（可能使用静态分析工具或另一个 LLM 调用）。
* 提示词 4：基于识别的问题重写或完善代码。
* 提示词 5：添加文档或测试用例。

在 AI 辅助软件开发等应用中，提示词链的效用源于其将复杂编码任务分解为一系列可管理的子问题的能力。这种模块化结构降低了每一步大型语言模型的操作复杂性。至关重要的是，这种方法还允许在模型调用之间插入确定性逻辑，实现中间数据处理、输出验证和工作流中的条件分支。通过这种方法，一个可能导致不可靠或不完整结果的单一多面请求被转换为由底层执行框架管理的结构化操作序列。

**7. 多模态和多步推理：** 分析具有不同模态的数据集需要将问题分解为更小的、基于提示词的任务。例如，解释包含带嵌入文本的图片、突出显示特定文本段的标签以及解释每个标签的表格数据的图像，需要这样的方法。

* 提示词 1：从用户的图像请求中提取和理解文本。
* 提示词 2：将提取的图像文本与其相应的标签链接起来。
* 提示词 3：使用表格解释收集的信息以确定所需的输出。

## 实操代码示例

实现提示词链的范围从脚本中的直接顺序函数调用到利用专门设计用于管理控制流、状态和组件集成的框架。诸如 LangChain、LangGraph、Crew AI 和 Google Agent Development Kit (ADK) 等框架提供了用于构建和执行这些多步过程的结构化环境，这对于复杂架构特别有利。

出于演示目的，LangChain 和 LangGraph 是合适的选择，因为它们的核心 API 明确设计用于组合操作链和图。LangChain 为线性序列提供基础抽象，而 LangGraph 扩展了这些能力以支持状态化和循环计算，这对于实现更复杂的 Agent 行为是必需的。此示例将专注于基础线性序列。

以下代码实现了一个两步提示词链，作为数据处理管道运行。初始阶段旨在解析非结构化文本并提取特定信息。后续阶段然后接收此提取的输出并将其转换为结构化数据格式。

要复制此过程，必须首先安装所需的库。这可以使用以下命令完成：

```bash
pip install langchain langchain-community langchain-openai langgraph
```

请注意，langchain-openai 可以替换为不同模型提供商的适当包。随后，必须为选定的语言模型提供商（如 OpenAI、Google Gemini 或 Anthropic）配置执行环境所需的 API 凭据。

```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

## 为了更好的安全性，从 .env 文件加载环境变量
## from dotenv import load_dotenv
## load_dotenv()
## 确保你的 OPENAI_API_KEY 在 .env 文件中设置

## 初始化语言模型（推荐使用 ChatOpenAI）
llm = ChatOpenAI(temperature=0)

## --- 提示词 1：提取信息 ---
prompt_extract = ChatPromptTemplate.from_template(
    "从以下文本中提取技术规格：\n\n{text_input}"
)

## --- 提示词 2：转换为 JSON ---
prompt_transform = ChatPromptTemplate.from_template(
    "将以下规格转换为 JSON 对象，使用 'cpu'、'memory' 和 'storage' 作为键：\n\n{specifications}"
)

## --- 使用 LCEL 构建链 ---
## StrOutputParser() 将 LLM 的消息输出转换为简单字符串。
extraction_chain = prompt_extract | llm | StrOutputParser()

## 完整的链将提取链的输出传递到转换提示词的 'specifications' 变量中。
full_chain = (
    {"specifications": extraction_chain}
    | prompt_transform
    | llm
    | StrOutputParser()
)

## --- 运行链 ---
input_text = "新款笔记本电脑型号配备 3.5 GHz 八核处理器、16GB 内存和 1TB NVMe 固态硬盘。"

## 使用输入文本字典执行链。
final_result = full_chain.invoke({"text_input": input_text})

print("\n--- 最终 JSON 输出 ---")
print(final_result)
```

这段 Python 代码演示了如何使用 LangChain 库处理文本。它利用两个独立的提示词：一个从输入字符串中提取技术规格，另一个将这些规格格式化为 JSON 对象。ChatOpenAI 模型用于语言模型交互，StrOutputParser 确保输出为可用的字符串格式。LangChain 表达式语言（LCEL）用于优雅地将这些提示词和语言模型链接在一起。第一个链 extraction_chain 提取规格。然后 full_chain 获取提取的输出并将其用作转换提示词的输入。提供了描述笔记本电脑的示例输入文本。full_chain 通过这两个步骤调用此文本进行处理。最后打印最终结果，这是一个包含提取和格式化规格的 JSON 字符串。

## 上下文工程和提示工程

上下文工程（见图 1）是在 token 生成之前系统地设计、构建和向 AI 模型提供完整信息环境的学科。这种方法论断言，模型输出的质量较少依赖于模型架构本身，而更多依赖于所提供上下文的丰富性。

![][image1]

图 1：上下文工程是为 AI 构建丰富、全面的信息环境的学科，因为此上下文的质量是实现高级 Agent 性能的主要因素。

它代表了从传统提示工程的重大演进，传统提示工程主要关注优化用户即时查询的措辞。上下文工程将此范围扩展到包括多个信息层，例如**系统提示词**，这是定义 AI 操作参数的基础指令集——例如，*"你是一名技术作家；你的语气必须正式而精确。"* 上下文通过外部数据进一步丰富。这包括检索的文档，其中 AI 主动从知识库中获取信息以告知其响应，例如提取项目的技术规格。它还包含工具输出，这是 AI 使用外部 API 获取实时数据的结果，例如查询日历以确定用户的可用性。这些显式数据与关键的隐式数据结合，如用户身份、交互历史和环境状态。核心原则是，即使是高级模型，在提供有限或构建不良的操作环境视图时，也会表现不佳。

因此，这种实践将任务从仅仅回答问题重新定义为为 Agent 构建全面的操作图景。例如，上下文工程化的 Agent 不仅会响应查询，而且首先会整合用户的日历可用性（工具输出）、与电子邮件收件人的专业关系（隐式数据）以及之前会议的笔记（检索的文档）。这使得模型能够生成高度相关、个性化和实用的输出。"工程"组件涉及创建健壮的管道以在运行时获取和转换此数据，并建立反馈循环以持续改进上下文质量。

要实现这一点，可以使用专门的调优系统来大规模自动化改进过程。例如，像 Google 的 Vertex AI 提示词优化器这样的工具可以通过系统地根据一组样本输入和预定义的评估指标评估响应来提高模型性能。这种方法对于在不同模型之间调整提示词和系统指令而无需大量手动重写非常有效。通过向这样的优化器提供样本提示词、系统指令和模板，它可以以编程方式完善上下文输入，为实现复杂上下文工程所需的反馈循环提供结构化方法。

这种结构化方法是区分基本 AI 工具与更复杂、上下文感知系统的关键。它将上下文本身视为主要组件，对 Agent 知道什么、何时知道以及如何使用该信息给予关键重要性。这种实践确保模型对用户的意图、历史和当前环境有全面的理解。最终，上下文工程是将无状态聊天机器人提升为高度能干、情境感知系统的关键方法论。

## 概览

**是什么：** 复杂任务在单个提示词内处理时通常会使 LLM 不堪重负，导致严重的性能问题。模型的认知负荷增加了错误的可能性，如忽略指令、失去上下文和生成错误信息。单体提示词难以有效管理多个约束和顺序推理步骤。这导致不可靠和不准确的输出，因为 LLM 未能解决多方面请求的所有方面。

**为什么：** 提示词链通过将复杂问题分解为一系列较小的、相互关联的子任务来提供标准化解决方案。链中的每一步使用聚焦的提示词执行特定操作，显著提高可靠性和控制力。一个提示词的输出作为下一个提示词的输入传递，创建逐步构建最终解决方案的逻辑工作流。这种模块化的分而治之策略使过程更易于管理、更易于调试，并允许在步骤之间集成外部工具或结构化数据格式。这种模式是开发能够规划、推理和执行复杂工作流的复杂多步 Agent 系统的基础。

**经验法则：** 当任务对于单个提示词过于复杂、涉及多个不同的处理阶段、需要在步骤之间与外部工具交互，或者在构建需要执行多步推理并维护状态的 Agent 系统时，使用此模式。

**视觉摘要**

![][image2]

图 2：提示词链模式：Agent 从用户接收一系列提示词，每个 Agent 的输出作为链中下一个 Agent 的输入。

## 关键要点

以下是一些关键要点：

* 提示词链将复杂任务分解为一系列更小的、聚焦的步骤。这有时被称为管道模式。
* 链中的每一步涉及 LLM 调用或处理逻辑，使用前一步的输出作为输入。
* 这种模式提高了与语言模型的复杂交互的可靠性和可管理性。
* 像 LangChain/LangGraph 和 Google ADK 这样的框架提供了强大的工具来定义、管理和执行这些多步序列。

## 结论

通过将复杂问题分解为一系列更简单、更易于管理的子任务，提示词链为指导大型语言模型提供了一个健壮的框架。这种"分而治之"策略通过一次专注于一个特定操作，显著提高了输出的可靠性和控制力。作为基础模式，它支持开发能够进行多步推理、工具集成和状态管理的复杂 AI Agent。最终，掌握提示词链对于构建能够执行远超单个提示词能力的复杂工作流的健壮、上下文感知系统至关重要。

## 参考文献

1. LangChain Documentation on LCEL: [https://python.langchain.com/v0.2/docs/core_modules/expression_language/](https://python.langchain.com/v0.2/docs/core_modules/expression_language/)
2. LangGraph Documentation: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)
3. Prompt Engineering Guide - Chaining Prompts: [https://www.promptingguide.ai/techniques/chaining](https://www.promptingguide.ai/techniques/chaining)
4. OpenAI API Documentation (General Prompting Concepts): [https://platform.openai.com/docs/guides/gpt/prompting](https://platform.openai.com/docs/guides/gpt/prompting)
5. Crew AI Documentation (Tasks and Processes): [https://docs.crewai.com/](https://docs.crewai.com/)
6. Google AI for Developers (Prompting Guides): [https://cloud.google.com/discover/what-is-prompt-engineering?hl=en](https://cloud.google.com/discover/what-is-prompt-engineering?hl=en)
7. Vertex Prompt Optimizer [https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer)

[image1]: ../images/chapter-1/image1.png

[image2]: ../images/chapter-1/image2.png